# **Challenge MOSEF: Bank Churn Prediction**

## English Version

## Project Description

This project was developed as part of the MOSEF Kaggle Challenge on **bank customer churn prediction**.  
The goal was to build a high-performance machine learning model capable of predicting whether a client would leave the bank (`Exited` = 1) or stay (`Exited` = 0).

---

## Data

The dataset was divided into two subsets:

- **Train:** 10,000 observations with 14 variables (including 11 key features)  
- **Test:** 5,000 observations with 13 variables (target variable `Exited` excluded)

---

## Data Preprocessing

- Outlier detection and removal  
- Feature engineering for categorical and numerical variables  
- Normalization using **RobustScaler**

---

## Modeling

- **Model used:** `CatBoostClassifier` (well-suited for categorical data and resistant to overfitting)  
- **Evaluation metric:** ROC-AUC  
- **Hyperparameter optimization:** Grid Search combined with stratified K-Fold Cross-Validation  

---

## Model Performance

- **Best ROC-AUC (cross-validation):** 0.9385  
- **Final validation ROC-AUC:** 0.9324  

---

## Authors

- [Alisa Chekalina](https://github.com/chekalisa)  
- [Carmen Cristea](https://github.com/CarmenParis)

---
## üá¨üáß French Version

## Description du projet

Ce projet a √©t√© r√©alis√© dans le cadre du challenge Kaggle MOSEF sur la pr√©diction du churn bancaire. L'objectif est de d√©velopper un mod√®le de machine learning performant capable de pr√©dire si un client quittera ou non la banque (√©tiquette binaire "Exited").

## Donn√©es

Les donn√©es sont divis√©es en deux ensembles :

Train (Entra√Ænement) : 10 000 observations avec 14 variables (dont 11 essentielles)

Test : 5 000 observations avec 13 variables (sans la variable cible "Exited")

## Pr√©traitement des donn√©es

- Gestion des valeurs aberrantes

- Feature Engineering

- Normalisation avec RobustScaler

## Mod√©lisation

**Mod√®le choisi** : CatBoostClassifier (adapt√© aux donn√©es cat√©gorielles et r√©sistant au surapprentissage)

**M√©trique d'√©valuation** : ROC-AUC

**Optimisation des hyperparam√®tres** : Grid Search + Validation crois√©e K-Fold (stratifi√©e)



## Performance du mod√®le

Meilleur score ROC-AUC : 0.9385 (validation crois√©e)

Score final sur validation : 0.9324

## Authors

- [Alisa Chekalina](https://github.com/chekalisa)
- [Carmen Cristea](https://github.com/CarmenParis)






